{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint, HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SQLDatabase.from_uri(\"sqlite:///movies.db\", sample_rows_in_table_info=0)\n",
    "\n",
    "def get_schema(_):\n",
    "    return db.get_table_info()\n",
    "\n",
    "\n",
    "def run_query(query):\n",
    "    print(f'Query being run: {query} \\n\\n')\n",
    "    return db.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE movies (\n",
      "\t\"index\" INTEGER, \n",
      "\tbudget INTEGER, \n",
      "\tgenres TEXT, \n",
      "\thomepage TEXT, \n",
      "\tid INTEGER, \n",
      "\tkeywords TEXT, \n",
      "\toriginal_language TEXT, \n",
      "\toriginal_title TEXT, \n",
      "\toverview TEXT, \n",
      "\tpopularity REAL, \n",
      "\tproduction_companies TEXT, \n",
      "\tproduction_countries TEXT, \n",
      "\trelease_date TEXT, \n",
      "\trevenue INTEGER, \n",
      "\truntime REAL, \n",
      "\tspoken_languages TEXT, \n",
      "\tstatus TEXT, \n",
      "\ttagline TEXT, \n",
      "\ttitle TEXT, \n",
      "\tvote_average REAL, \n",
      "\tvote_count INTEGER, \n",
      "\t\"cast\" TEXT, \n",
      "\tcrew TEXT, \n",
      "\tdirector TEXT\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(get_schema(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm(load_from_hugging_face=True):\n",
    "    if load_from_hugging_face:\n",
    "        llm = HuggingFaceEndpoint(\n",
    "            repo_id=\"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
    "            task=\"text-generation\",\n",
    "            provider=\"hyperbolic\",  # set your provider here\n",
    "        )\n",
    "\n",
    "        return ChatHuggingFace(llm=llm)\n",
    "    \n",
    "    return ChatOpenAI(model=\"gpt-4\", temperature=0.0)\n",
    "\n",
    "\n",
    "def write_sql_query(llm):\n",
    "    template = \"\"\"Based on the table schema below, write a SQL query that would answer the user's question:\n",
    "    {schema}\n",
    "\n",
    "    Question: {question}\n",
    "    SQL Query:\"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"Given an input question, convert it to a SQL query. No pre-amble. \"\n",
    "            \"Please do not return anything else apart from the SQL query, no prefix aur suffix quotes, no sql keyword, nothing please\"),\n",
    "            (\"human\", template),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        RunnablePassthrough.assign(schema=get_schema)\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_user_query(query, llm):\n",
    "    template = \"\"\"Based on the table schema below, question, sql query, and sql response, write a natural language response:\n",
    "    {schema}\n",
    "\n",
    "    Question: {question}\n",
    "    SQL Query: {query}\n",
    "    SQL Response: {response}\"\"\"\n",
    "\n",
    "    prompt_response = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"Given an input question and SQL response, convert it to a natural language answer. No pre-amble.\",\n",
    "            ),\n",
    "            (\"human\", template),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    full_chain = (\n",
    "        RunnablePassthrough.assign(query=write_sql_query(llm))\n",
    "        | RunnablePassthrough.assign(\n",
    "            schema=get_schema,\n",
    "            response=lambda x: run_query(x[\"query\"]),\n",
    "        )\n",
    "        | prompt_response\n",
    "        | llm\n",
    "    )\n",
    "\n",
    "    return full_chain.invoke({\"question\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query types to try out:\n",
    "\n",
    "# 1. Straight forward queries: Give me the name of 10 Artists\n",
    "# 2. Querying for multiple columns: Give me the name and artist ID of 10 Artists\n",
    "# 3. Querying a table by a foreign key: Give me 10 Albums by the Artist with ID 1\n",
    "# 4. Joining with a different table: Give some Albums by the Artist name Audioslave'\n",
    "# 5. Multi-level Joins: Give some Tracks by the Artist name Audioslave'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query being run: SELECT revenue FROM movies ORDER BY revenue DESC LIMIT 1 OFFSET 1 \n",
      "\n",
      "\n",
      "The second highest revenue is 1,845,034,188.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# write_sql_query(llm=get_llm(load_from_hugging_face=True)).invoke({\"question\": \"Give me 10 Artists\"})\n",
    "query = 'what is the second highest revenue'\n",
    "response = answer_user_query(query, llm=get_llm(load_from_hugging_face=True))\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query being run: SELECT MIN(revenue) FROM movies ORDER BY revenue ASC LIMIT 1 OFFSET 1 \n",
      "\n",
      "\n",
      "The second lowest revenue for a movie in the dataset is 12,405,275.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# write_sql_query(llm=get_llm(load_from_hugging_face=True)).invoke({\"question\": \"Give me 10 Artists\"})\n",
    "query = 'what is the second lowest revenue'\n",
    "response = answer_user_query(query, llm=get_llm(load_from_hugging_face=True))\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
